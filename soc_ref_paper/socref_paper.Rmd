---
title             : "Children's social information gathering reflects sensitivity to uncertainty"
shorttitle        : "Information gathering reflects uncertainty"

author: 
  - name          : "Emily Hembacher"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Stanford, CA, 94305"
    email         : "ehembach@stanford.edu"
  - name          : "Benjamin deMayo"
    affiliation   : "1"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Stanford University"
  
author_note: |

abstract: |
  We examined children's spontaneous information gathering in response to lexical uncertainty. Children ages 2-5 (n=160) identified the referents of familiar and novel labels. Referential ambiguity was manipulated through the number of objects present and their familiarity (Experiments 1 and 2), and the availability of referential gaze (Experiment 2). In both experiments, children sought disambiguating social information more often while responding when the referent was ambiguous. In Experiment 2, 3- to 4-year-olds also demonstrated sensitivity to graded referential evidence. These results suggest that social information gathering is an active learning behavior that could contribute to language acquisition in early childhood.
  
keywords          : "information gathering; help seeking; word learning; uncertainty."
wordcount         : "X"

bibliography      : ["socref.bib"]

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no

lang              : "english"
class             : "man"
output            : papaja::apa6_pdf
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = FALSE, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=FALSE, warning=FALSE, cache=TRUE, message=FALSE, sanitize = TRUE)
```

```{r, libraries}
library(papaja)
library(tidyverse)
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(langcog)
library(ggplot2)
library(rjson)
library(stringr)
library(lme4)
library(knitr)
library(markdown)
library(lmerTest)
library(ggthemes)
library(psych)
library(broman)
library(kmr)
library(magrittr)
library(stargazer)
```

Early childhood is marked by the rapid acquisition of new concepts, rules, and language, and theories of cognitive development have increasingly focused on the active role that children play in these cognitive achievements [@Xu2013]. Recent work highlights that young children actively explore [@Schulz2007] and ask questions [@Chouinard2007; @Ruggeri2017] in ways that seem specifically targeted to reduce uncertainty. Furthermore, they benefit from the ability to control the timing and content of their learning [@Markant2016]. 

This burgeoning literature suggests that in many contexts children are able to identify gaps in knowledge and act intentionally to fill those gaps. However, it is still unclear how the reciprocal processes of uncertainty monitoring and information gathering operate across different learning domains and across development. Although the ability to monitor epistemic uncertainty is logically prerequisite to active learning, evidence about young children’s metacognitive abilities has been mixed and appears task-dependent. While some learning domains have been studied repeatedly from an active-learning perspective (e.g., memory; [refs] causal learning [refs]), others have been relatively ignored. In particular, we know little about children's monitoring of lexical uncertainty and corresponding active learning behaviors.

Awareness of lexical uncertainty or ignorance could be an important mechanism for language acquisition. Knowing that you have incomplete linguistic information (e.g., realizing that a word is unfamiliar or that you can’t retrieve the label for an object or concept) could prompt active learning behaviors including asking for help or seeking other disambiguating referential information. However, there is still limited evidence about young children’s tracking of lexical ambiguity or associated active learning behaviors. In the following section we review previous evidence about linguistic uncertainty monitoring and about uncertainty monitoring in other domains.

##Development of uncertainty monitoring

A few previous studies have investigated children’s awareness of lexical uncertainty.
One study examined whether 2-year-olds could report on their own lexical ignorance when presented with unfamiliar words or objects (@Marazita2004). They found that 2.5-year-olds were better than chance at reporting that they did not know the name for an unfamiliar item when asked, but still reported that they knew the label ##% of the time. When presented with nonsense words in a story, they reported that they know what the word meant ##% of the time. Research in the selective trust literature has shown that children are less willing to accept a new label for an unfamiliar object from a previously inaccurate informant compared to an accurate one, suggesting that young children do not treat all incoming linguistic input equally.  describe lyons2011 In one study, 3- to 5-year-olds used a pictorial confidence scale to report on their certainty in their responses in perceptual discrimination and lexical identification tasks [@Lyons2011a].  Preschoolers reported being less confident when they responded incorrectly, suggesting that they were aware of their likelihood of accuracy based on their epistemic states. 

Other studies have investigated the development of uncertainty monitoring during early childhood in non-linguistic domains. Overall, when asked explicitly about their confidence or knowledge, young children tend to overestimate their likely accuracy and fail to recognize their own ignorance. Hembacher and Ghetti (2014) [-@Hembacher2014] investigated children’s confidence in their memories for pictures they had studied using a pictorial confidence scale similar to Lyons et al. They found that 3-year-olds were equally confident for correct and incorrect answers, while 4- and 5-year-olds were more confident for their correct answers [@Hembacher2014]. Furthermore, only 5-year-olds were most confident about their memories for images they had studied for longer. This is in contrast to Lyons et al. and Coughlin, Hembacher, Lyons and Ghetti (2014) [-@Coughlin2014] who found that even 3-year-olds were less confident for their incorrect responses in perceptual and lexical tasks, although there were developmental improvements across the age span tested. Thus, children’s uncertainty monitoring may depend on the cognitive task being reflected on.

Another series of studies has demonstrated children’s failures to recognize their ignorance or comprehension failures. Markman [-@Markman1977] gave preschoolers incomplete instructions to complete a task (i.e., a card game or a magic trick), and asked them if they knew how to proceed. Even after multiple prompts (e.g., “What do you think?”, “Do you have any questions?”), children did not indicate that they were unsure how to play the game. On average, 1st graders did not ask any questions until they were asked “Can you tell me how to play?”, which presumably forced them to confront their ignorance of the critical steps.  Children also report knowing the unseen contents of a box if they have seen several items that may have gone into the box (i.e., they have “partial exposure” to the contents) until the age of 6 [@Rohwer2012]. 

In sum, there is mixed evidence about young children’s metacognitive competencies in tasks that require explicit responses from children. However, these paradigms may underestimate children’s ability to track epistemic uncertainty and act on it. One possibility is that children’s tracking of uncertainty is apparent in their spontaneous information-seeking behaviors before they can report on it explicitly. In the following section we review evidence that young children who fail explicit metacognitive tasks nonetheless explore and seek information selectively based on uncertainty.

##Development of Spontaneous Information-seeking

First, a collection of studies have taken inspiration from comparative metacognition research and asked whether children's spontaneous information-seeking behaviors track uncertainty. For example, Call and Carpenter [-@Call2001] had 2-year-olds choose between several tubes to find a hidden sticker. They found that the toddlers were more likely to peek inside a tube before choosing when they had not seen the baiting of the tubes compared to when they had, suggesting they were aware of their knowledge or ignorance and selectively sought confirmatory evidence before committing to a response when they did not know a sticker’s location. 

Other studies have shown that young children can opt out of responding or seek help when uncertain of their memories. Balcomb and Gerken [-@Balcomb2008] had 3.5-year-olds complete a memory task in which they could opt out of responding to individual trials. Children performed worse on trials they had opted out of when they were forced to answer them later on, suggesting that they used the opt-out option strategically to avoid answering when they were uncertain about their responses.  In another study, Goupil, Romand-Monnier, and Kouider [-@Goupil2016] trained 20-month-olds to look at their parents if they needed help with a memory task in which they had to locate a hidden toy. Toddlers were more likely to seek help when they were completely ignorant of the toy’s location, and when the task was more difficult because the delay between hiding and test was longer. These studies suggest that young children can monitor the strength (or absence) of memories and seek information when they are less likely to respond correctly.

There is also evidence that young children selectively explore when evidence is confounded (i.e., when existing evidence supports multiple causal hypotheses). For example, Schulz & Bonawitz [-@Schulz2007] found that preschoolers spent more time playing with a toy when they witnessed confounded evidence about its causal structure. Children who experienced a demonstration of a toy in which two levers were simultaneously depressed and caused two simultaneous events (a toy duck and puppet popping up) spent more time playing with that toy compared to children who saw a demonstration in which one lever was depressed at a time, revealing the unique function of each lever. This finding is consistent with the prediction that preschool-aged children track causal ambiguity and spontaneously explore more when they do not have sufficient evidence to isolate a cause for an effect. 

Infants have also been shown to seek information selectively under conditions of ambiguity, and explore or allocate attention to information sources that are most likely to disambiguate. For example, in one pair of studies, 7- and 8-month-olds attended longer to visual displays [@Kidd2012] or auditory stimuli [@Kidd2014] that were neither too complex nor too simple, and thus afforded the greatest learning opportunity. Twelve-month-old infants have also been shown to track the likelihood of different events (e.g., a red ball exiting a container full of moving red and blue balls) based on reasoning about multiple cues — numerosity (the number of red compared to blue balls), physical distance (the distance from a red ball to the opening of the container) and time (how long the scene was occluded before the ball left the container). Intriguingly, infants’ surprisal (looking time) tracked with uncertainty about the likelihood of events — for example, at intermediate occlusion times, infants’ looking time was graded with respect to distance and numerosity in an additive fashion [@Teglas2011]. 

##Current study

The present study investigates children's information-seeking behaviors on the basis of lexical ambiguity. Specifically, we ask whether children are more likely to seek disambiguating social information by looking at the experimenter when they are uncertain of the referent of a label they have been asked to act on. We chose to examine this ability in early childhood (ages 2 to 5), because, as discussed, research under a metacognitive framework has identified this as a developmental period in which children improve substantially in their ability to identify their own ignorance and uncertainty [@Hembacher2014; @Coughlin2014; @Lyons2011a; @Rohwer2012]. 

We manipulated lexical ambiguity by adapting a paradigm used by Vaish, Demir and Baldwin (2011) [-@Vaish2011] to test infants’ selective gaze referencing. In that study, 12- to 18-month-olds heard an experimenter produce a label for an object in the presence of one or two novel objects. Infants looked at the experimenter more often when there were two objects present, and the referent was thus ambiguous. This evidence is interpreted as suggesting that older infants recognize the need for disambiguating information, and reference the speaker’s gaze direction accordingly. 

Here, we expand on this finding to ask whether 2- to 5-year-olds seek social information throughout the course of a task in which a speaker labels an object and asks the child to put the named object in a bucket. Similar to Vaish et al., we examined the number of times children looked up at the experimenter depending on the ambiguity of the label. We examine children’s use of social information during labeling, similar to Vaish et al., but also during children’s decision about which object to place in the bucket. We also control for the number of objects by including unambiguous trials with two familiar objects, one familiar object, and one novel object, and the ambiguous trials with two novel objects. 

In Experiment 2, we additionally manipulate the amount of referential evidence available allowing us to investigate whether preschoolers’ information-gathering is sensitive to graded lexical uncertainty (i.e., whether they are increasingly likely to answer independently without seeking information as the amount of referential evidence increases). There are several reasons to investigate children’s sensitivity to graded evidence. First, probabilistic models of cognition and learning require that individuals be able to track the amount of evidence for alternative beliefs (and corresponding uncertainty), perhaps through heuristics such as “win-stay lose-sample” [@Bonawitz2014]. If preschool-aged children do track accumulating evidence as assumed by these models, their information-gathering behaviors should be graded with respect to the amount of evidence for a belief.

More generally, a complete theory of early metacognition and learning should encompass children’s ability to respond appropriately to graded evidence. Metacognitive theories assume that effective behavioral regulation and response selection rely on individuals' abilities to track the likelihood of being correct based not only on complete knowledge or ignorance, but on graded evidence [@Lyons2011]. For example, having more information in support of a belief should make individuals more willing to share that information with others, and having less information should motivate help-seeking [@Ghetti2013]. In sum, the present study investigates whether children ages 2 to 5 seek disambiguating social information on the basis of lexical ambiguity. If so, this could be an important mechanism for language acquisition during early childhood. 

```{r design,  fig.cap= "Study design for Experiments 1 and 2. Children were shown one or two objects, heard a label, and were asked to place the labeled object in a bucket. Referential ambiguity was manipulated through the familiarity of the objects present and through the availability of referential gaze."}
img <- png::readPNG("figs/socref_design.png")
grid::grid.raster(img)
```

# Experiment 1

In Experiment 1, we examined whether children would visually reference a speaker more often when the speaker produced a referentially ambiguous label compared to an unambiguous label. Children sat across from an experimenter who labeled an object on the table between them (Figure \ref{fig:design}). The experimenter then asked the child to place the named object in a bucket. Across trials, there were either one or two objects on the table, which were either familiar or novel to the child. This design allowed us to test whether merely having more than one object present is sufficient to increase information gathering, or if referential ambiguity (and thus epistemic uncertainty) is the underlying factor. If the latter is true, we expected children to increase their looking to the experimenter only on trials with two unfamiliar objects, when the object-label mapping was not known and could not be inferred. 

We were interested in the amount of information gathering children exhibited across the trial. We considered four different phases of each trial based on the notion that children might expect different social information at different stages of the task. Specifically, we predicted that children might expect the speaker's gaze direction to be informative during the labeling itself, as speakers tend to look at objects they refer to. We also predicted that later in the trial, as children reached for an object and placed it in the bucket, they might expect evaluative feedback about their choice (e.g., facial expressions of encouragement or discouragement). 

```{r}
load("soc_ref_e2.RData")
plength2 <- psych::describeBy(d$phase_length, d$phase_name)

load("soc_ref_e1.RData")

age_months <- d %>%
  group_by(age_years) %>%
  multi_boot_standard(col = "age_months")

age_months$age_years <- factor(age_months$age_years,
levels = c(2, 3, 4, 5),
labels = c("two", "three", "four", "five"))

halfs<- d %>%
  mutate(first_half = between(trial, 1, 4)) 

plength1 <- psych::describeBy(d$phase_length, d$phase_name)

phases1 <- data.frame()
phases2 <- data.frame()
phases1 <- bind_rows(phases1, plength1$label, plength1$slide, plength1$planning, plength1$response)%>%
  select(mean, sd)%>%
  mutate(phase = c("label","slide","planning","response"), Experiment = "1")
phases2 <- bind_rows(phases2, plength2$label, plength2$slide, plength2$planning, plength2$response)%>%
  select(mean, sd)%>%
  mutate(phase = c("label","slide","planning","response"), Experiment = "2")

phases <- bind_rows(phases1, phases2)%>%
  select(Experiment, phase, mean, sd)

save(phases, file = "phases.RData")
```

## Methods

### Participants
We recruited a planned sample of 80 children ages 2-5 years from the Children’s Discovery Museum in San Jose, California^[Planned sample size, exclusion criteria, and analysis plan preregistered at https://osf.io/y7mvt.]. The sample included 20 2-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="two"], 1)` months), 20 3-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="three"], 1)` months), 20 4-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="four"], 1)` months), and 20 5-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="five"], 1)` months). An additional 20 children participated but were removed from analyses because they heard English less than 75% of the time at home (*n* = 10), because they were unable to complete at least half of the trials in the task (*n* = 4), because of parental interference (*n* = 1), or due to experimenter or technical errors (*n* = 5). 

### Stimuli and Design
Children were presented with one or two objects, heard a label, and were asked to put the labeled object in a bucket. Half of the objects were selected to be familiar to children (e.g., a cow) and half were selected to be novel (e.g., an usual-looking nozzle). The familiar items had names that the majority of children recognize by 24 months [@Frank2016]. There were four possible trial types based on the number and familiarity of the objects present: one familiar object (F), one novel object (N), two familiar objects (FF), and two novel objects (NN). There were three trials of each type, for a total of twelve trials. Trial types were presented sequentially in an order that was counterbalanced across participants. The assignment of individual objects to trial types was counterbalanced. On F and FF trials, the familiar label for the target object was used (e.g., “cow”). On N and NN trials, a novel label was used (e.g., “dawnoo”). 

The critical manipulation was of referential ambiguity; F and FF trials were referentially unambiguous, as children were expected to be certain about the objects and their labels. Similarly, on N trials, children were expected to be certain about the label referent as there was only one option. However, NN trials were referentially ambiguous, as the novel label could apply to either novel object.

Throughout the task, the experimenter never gazed at the object they were labeling, or responded to children's verbal or non-verbal bids for help by indicating the correct object. Thus, children were expected to remain uncertain about the referent for the duration of the trial when two novel objects were present. 

### Procedure

Throughout the study, the child sat at one end of a large circular table, and the experimenter stood at the opposite end. Each trial proceeded as follows: the experimenter placed one or two objects on the left and/or right sides of the table, out of reach of the child so that the child could not interact with the toys during the labeling event. For one-object trials, the location of the object (left or right) alternated between trials. 
After placing the objects, the experimenter said “Hey look, there’s a (target) here.” The experimenter gazed at the center of the table rather than the object they labeled. The experimenter waited approximately two seconds based on a visual metronome placed within view before saying, “Can you put the (target) in the bucket?” They then pushed the object(s) forward within reach of the child, and placed a plastic bucket in the center of the table, also within reach of the child. If the child did not respond within 10 seconds, the experimenter repeated the question. The experimenter provided no accuracy feedback to children throughout the trial. After the child placed an object in the bucket, the experimenter said "okay!" or "thank you!" to maintain a positive interaction without providing information about accuracy. Prior to the twelve experimental trials, there were two training trials: an F trial and an FF trial, to acquaint the child with the procedure. If children chose the wrong object on the FF trial (which happened rarely), they were corrected. A camera placed to the side of the experimenter captured the participant’s face, so that looking behavior could be coded from video.

### Coding procedure and analytic plan

```{r}
load("soc_ref_e1.RData")
#how many trials are missing because of child off-task?
missing <- d %>%
  group_by(age_years)%>%
  summarise(excluded = mean(exclude))

missingtwo <- missing$excluded[missing$age_years == 2]
missingthree <- missing$excluded[missing$age_years == 3]
missingfour <- missing$excluded[missing$age_years == 4]
missingfive <- missing$excluded[missing$age_years == 5]
```

Videos were coded using DataVyu software (http://datavyu.org). For each participant, we coded the *number of times* they referenced the experimenter throughout each trial. An alternative analytic option would be to simply code *whether or not* children looked at the experimenter. However, during piloting, we found that most children looked up to the experimenter at least once while they were labeling the object, suggesting that a binary measure of looking would not be meaningful. 

Because we were interested in the precise circumstances in which children feel uncertain enough to reference a speaker, we coded the number of looks that occurred during four distinct phases of the trial: a *label* phase, which began at the utterance of the label and ended when the experimenter began to slide the objects, a *slide* phase, in which the experimenter slid the object(s) into the child’s reach, a *planning* phase, which began at the end of the slide and ended when the child touched an object, and a *response* phase, which began when the child touched an object and ended when the child released the object into the bucket. If a look began in one phase but continued into another, we counted it as a look in both phases.

We also noted any trials that should be excluded from analyses due to the child's interference with the timing of the trial (e.g., talking over the experimenter), experimenter error, or outside distractions that interfered with the timing of the trial (e.g., noise from a sibling). These trial-wise exclusion criteria were preregistered. In total, we excluded `r broman::myround(missingtwo*100, 1)`% of trials from 2-year-olds, `r broman::myround(missingthree*100, 1)`% of trials from 3-year-olds, `r broman::myround(missingfour*100, 1)`% of trials from 4-year-olds, and `r broman::myround(missingthree*100, 1)`% of trials from 5-year-olds on this basis. 
A second coder independently scored the number of looks for one third of the trials for each participant to establish reliability. Inter-rater reliability for the number of looks in each phase was high, intraclass correlation *r* = .97, *p* < .001.

Table \ref{tab:phases} displays the average durations of each of the four phases. The *label* and *response* phases are longer on average than the *planning* and *slide* phases. However, note that we are interested in comparing the amount of looking across ambiguity conditions and not across phases directly.

To quantify the effects of the number and familiarity of objects on children's looking, along with any developmental trends, we planned to fit a linear mixed-effects regression. “Mixed-effects models account for both fixed factors and random factors (such as participants and stimuli). As such, they provide a more accurate estimate of whether results will generalize beyond the participants and items that were sampled [@Baayen2008]. As recommended by Barr, Levy, Scheepers, and Tily (2013) [-@Barr2013], we begin with a maximal model with the following structure and trim according to our standard laboratory procedures^[Standard laboratory analytic procedures available at https://osf.io/zqzsu/wiki/home/]: `number of looks ~ number of objects * familiarity * phase * age in months + (number of objects * familiarity | subject) + (1 | trial)`. Random effects are denoted by parentheses. This model specification was preregistered, as noted above. 

## Results and Discussion

###Accuracy

```{r echo = FALSE}
#how often did children select two objects or no objects?
ids <- d %>%
 distinct(SID)

trials <- d %>%
 distinct(trial)

n <- length(ids$SID)*length(trials$trial)
n_two <- n/2 #number of two-object trials
n_two_group <- n_two/4 #number of two-object trials per age group

res <- d %>%
  filter(num_objs == 2)%>%
  distinct(SID, trial, response_orig, familiarity, acc, age_years)

#how many kids sometimes picked 2 objects?
two_objs <- res %>%
  filter(response_orig == "LR" | response_orig == "RL")

length(unique(two_objs$SID[two_objs$age_years == 2]))
length(unique(two_objs$SID[two_objs$age_years == 3]))
length(unique(two_objs$SID[two_objs$age_years == 4]))
length(unique(two_objs$SID[two_objs$age_years == 5]))

two_kids <- unique(two_objs$SID)

#how often do kids pick 2 objects on 2-object trials?
nc <- length(res$acc[res$response_orig == "NC"])/n_two
b <- length(res$acc[res$response_orig == "B"])/n_two
lr <- length(res$acc[res$response_orig == "LR"])/n_two
rl <- length(res$acc[res$response_orig == "RL"])/n_two
tot <- 100*(lr + rl + b) #percent of trials with two objects placed in bucket

b2 <- length(res$acc[res$response_orig == "B" & res$age_years == 2])/n_two_group
b3 <- length(res$acc[res$response_orig == "B" & res$age_years == 3])/n_two_group
b4 <- length(res$acc[res$response_orig == "B" & res$age_years == 4])/n_two_group
b5 <- length(res$acc[res$response_orig == "B" & res$age_years == 5])/n_two_group

lr2 <- length(res$acc[res$response_orig == "LR" & res$age_years == 2])/n_two_group
lr3 <- length(res$acc[res$response_orig == "LR" & res$age_years == 3])/n_two_group
lr4 <- length(res$acc[res$response_orig == "LR" & res$age_years == 4])/n_two_group
lr5 <- length(res$acc[res$response_orig == "LR" & res$age_years == 5])/n_two_group

rl2 <- length(res$acc[res$response_orig == "RL" & res$age_years == 2])/n_two_group
rl3 <- length(res$acc[res$response_orig == "RL" & res$age_years == 3])/n_two_group
rl4 <- length(res$acc[res$response_orig == "RL" & res$age_years == 4])/n_two_group
rl5 <- length(res$acc[res$response_orig == "RL" & res$age_years == 5])/n_two_group

tot2 <- 100*(lr2 + rl2 + b2) #percent of 2obj trials with two objects placed in bucket
tot3 <- 100*(lr3 + rl3 + b3) #percent of 2obj trials with two objects placed in bucket
tot4 <- 100*(lr4 + rl4 + b4) #percent of 2obj trials with two objects placed in bucket
tot5 <- 100*(lr5 + rl5 + b5) #percent of 2obj trials with two objects placed in bucket

#are trials with 2 objects chosen more likely to be novel?

nov_t <- d %>%
  filter(num_objs == 2)%>%
  distinct(SID, trial, response_orig, familiarity, acc, age_years)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL" | response_orig == "B")%>%
  group_by(SID, age_years, familiarity)%>%
  summarise(both = mean(both))

nov <- d %>%
  filter(num_objs == 2)%>%
  distinct(SID, trial, response_orig, familiarity, acc, age_years)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL" | response_orig == "B")%>%
  group_by(age_years, familiarity)%>%
  summarise(both = mean(both))

t_nov_2 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 2], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 2], paired = TRUE)

t_nov_3 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 3], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 3], paired = TRUE)

t_nov_4 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 4], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 4], paired = TRUE)

t_nov_5 <- t.test(nov_t$both[nov_t$familiarity == "familiar" & nov_t$age_years == 5], nov_t$both[nov_t$familiarity == "novel" & nov_t$age_years == 5], paired = TRUE)

#when kids put two objects in bucket, do they put the correct one in first if there is a correct answer?

cor <- d %>%
  filter(num_objs == 2, !is.na(acc), response_orig != "B")%>%
  distinct(SID, trial, response_orig, familiarity, acc, age_years)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL")

acc_sum <- cor%>%
  filter(acc == 1)%>%
  group_by(age_years)%>%
  summarize(both = sum(both))

both_sum <- cor%>%
  group_by(age_years)%>%
  summarize(both = sum(both))
```


```{r}
#Get accuracy for BOTH experiments for table
acc_mss_e1 <- d%>%
  filter(!is.na(acc),familiarity == "familiar", exclude == 0, num_objs == 2)%>%
  mutate(trial_type = "FF", Gaze = "no gaze")%>%
  group_by(trial_type, Gaze, age_years)%>%
  multi_boot_standard(col = "acc")%>%
  mutate(Exp = "1")

acctab_e1 <- d%>%
  filter(!is.na(acc),familiarity == "familiar", exclude == 0, num_objs == 2)%>%
  group_by(age_years)%>%
  multi_boot_standard(col = "acc")

acctab_e1$age_years <- as.factor(acctab_e1$age_years)
```  

```{r acce1, fig.cap='Accuracy for FF trials in Experiment 1. Error bars are 95 percent confidence intervals.'}
ggplot(acctab_e1, aes(age_years, mean)) +
  geom_bar(stat="identity", position = "dodge") + 
  geom_linerange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
             position = position_dodge(width = .9))  +
  ggthemes::theme_few() + 
  labs(x = "Age in Years", y = "Accuracy")
```

```{r phasetable, echo = FALSE, results="asis"}
load("phases.RData")

names(phases) <- c('Experiment','Phase','Mean Duration', 'SD')

print(xtable(phases,
             label = "tab:phases",
             caption = "Phase Durations (in ms)",
             digits=c(0,0,0,0,0)),
      include.rownames=FALSE,
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom',
      table.placement = "b",
      floating = TRUE,
      type = "latex",
      hline.after = c(-1,0, 4,nrow(phases)),
      comment = F)
```

```{r}
load("soc_ref_e1.RData")
#t-test for 2-yo acc
acc_t <- d%>%
  filter(!is.na(acc), exclude == 0)%>%
  group_by(SID, age_years)%>%
  summarise(acc= mean(acc))

acctest <- t.test(acc_t$acc[acc_t$age_years == 2], mu=.5)
```

We examined children's accuracy for those trials in which a correct response was possible (i.e., FF trials). Children sometimes put two items in the bucket (2-year-olds: `r broman::myround(tot2, 1)`% of 2-object trials; 3-year-olds: `r broman::myround(tot3, 1)`%; 4-year-olds: `r broman::myround(tot4, 1)`%; 5-year-olds: `r broman::myround(tot5, 1)`%), despite instructions to choose only one. The first object children put in the bucket was coded as their response. Children in each age group were equally likely to put two objects in the bucket for familiar and unfamiliar trials (2-year-olds: *t*(`r t_nov_2$parameter`) = `r broman::myround(t_nov_2$statistic, 2)`, *p* =`r broman::myround( t_nov_2$p.value, 2)`; 3-year-olds: *t*(`r t_nov_3$parameter`) = `r broman::myround(t_nov_3$statistic, 2)`, *p* =`r broman::myround( t_nov_3$p.value, 2)`; 4-year-olds: *t*(`r t_nov_4$parameter`) = `r broman::myround(t_nov_4$statistic, 2)`, *p* =`r broman::myround(t_nov_4$p.value, 2)`; 5-year-olds: *t*(`r t_nov_5$parameter`) = `r broman::myround(t_nov_5$statistic, 2)`, *p* =`r broman::myround(t_nov_5$p.value, 2)`), suggesting that they put two objects in the bucket because it was a fun activity and difficult to inhibit, and not because they did not know the referent. Among FF trials in which children placed two items in the bucket, they put the correct item in first about half of the time (8/19 trials total for 2-year-olds; 5/6 for 3-year-olds; 0/2 for 4-year-olds; 2/4 for 5-year-olds). 

Children also occasionally declined to choose an item (`r broman::myround(nc*100, 1)`% of trials); these trials are excluded from accuracy analyses. Children's accuracy is displayed in Figure \ref{fig:acce1}. Overall children generally chose the correct item for FF trials, indicating that they understood the task and were motivated to answer correctly. While 3- to 5-year-olds performed close to ceiling (92% - 99%), 2-year-olds were less accurate (76%), but still performed significantly above chance (*t*(19) = `r broman::myround(acctest$statistic, 1)` , *p* < .001).

```{r}
rm(list=ls())
load("soc_ref_e1.RData")
```

```{r}
#get means for plot
msslooks <- filter(d, exclude == 0 | response_orig != "LR" | response_orig != "RL") %>%
  group_by(SID, phase_name, num_objs, familiarity, age_years) %>%
  summarise(num_looks = mean(num_looks))

mslooks <- filter(d, exclude == 0 | response_orig != "LR" | response_orig != "RL") %>%
  group_by(phase_name, familiarity, num_objs, age_years) %>%
  multi_boot_standard(col = "num_looks") 

msslooks_phases <- filter(d, exclude == 0) %>%
  group_by(phase_name) %>%
  summarise(num_looks = mean(num_looks))

msslooks$phase_name <- factor(msslooks$phase_name, levels = c("label","slide", "planning", "response"))
mslooks$phase_name <- factor(mslooks$phase_name, levels = c("label","slide", "planning", "response"))

msslooks$num_objs <- factor(msslooks$num_objs,
levels = c(1,2),
labels = c("One object", "Two objects"))

mslooks$num_objs <- factor(mslooks$num_objs,
levels = c(1,2),
labels = c("One object", "Two objects"))

msslooks$familiarity <- factor(msslooks$familiarity,
levels = c("familiar", "novel"),
labels = c("familiar (F)", "novel (N)"))

mslooks$familiarity <- factor(mslooks$familiarity,
levels = c("familiar", "novel"),
labels = c("familiar (F)", "novel (N)"))

msslooks$age_years <- factor(msslooks$age_years,
levels = c(2, 3, 4, 5),
labels = c("2 years", "3 years", "4 years", "5 years"))

mslooks$age_years <- factor(mslooks$age_years,
levels = c(2, 3, 4, 5),
labels = c("2 years", "3 years", "4 years", "5 years"))
```


```{r resultse1,fig.width=8, fig.height=6, fig.cap='Results of Experiment 1. Number of looks to the experimenter based on phase, the number and familiarity of objects present, and age. Age in months was entered as a continuous variable in regression models but is presented here as a categorical variable for visual simplicity. Error bars are 95 percent confidence intervals.'}

ggplot(msslooks, aes(x = phase_name, y = num_looks, 
               col = familiarity, group = familiarity)) + 
  geom_line(data = mslooks, aes(y = mean)) + 
  geom_pointrange(data = mslooks, 
                  aes(y = mean, ymin = summary_ci_lower, ymax = summary_ci_upper), 
                  position = position_dodge(width =.1)) + 
  facet_grid(age_years ~ num_objs) +
  scale_y_continuous(limits=c(0,2), breaks=c(0,1,2)) +
  theme(axis.text.x = element_text(angle = 0, hjust = .5, vjust = .5)) + 
  labs(x = "Phase", y = "Number of Looks") +
  ggthemes::theme_few() 
```

```{r include = FALSE}
lmer_data <- d %>%
  filter(!exclude) %>%
  mutate(num_objs = factor(num_objs), 
         familiarity = factor(familiarity), 
         age_c = as.numeric(langcog::scale(age_months, scale=FALSE)),
         phase_name = factor(phase_name),
         soc_ref = social_ref)
```

```{r lmer_e1, results="asis"}
l_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "label")))

s_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "slide")))

p_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "planning")))

r_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs | SID),
           data = filter(lmer_data, phase_name == "response")))
```

```{r echo = FALSE}
#histogram for number of looks by phase. 
load("soc_ref_e1.RData")

hist_e1 <- d %>%
   select(phase_name, num_looks)%>%
  mutate(Experiment = "Experiment 1")

load("soc_ref_e2.RData")

hist_e2 <- d %>%
   select(phase_name, num_looks)%>%
  mutate(Experiment = "Experiment 2")

hist<- hist_e1%>%
  bind_rows(hist_e2)

hist$phase_name <- factor(hist$phase_name,
levels = c("label", "slide", "planning", "response"),
labels = c("Label", "Slide", "Planning", "Response"))
```

```{r hist, fig.width=6, fig.cap='Distribution of the number of looks to the speaker in each phase.'}
 ggplot(hist, aes(num_looks, fill = num_looks)) +
  geom_histogram(stat = "count") +
   facet_grid(Experiment~phase_name) +
  ggthemes::theme_few() + 
  labs(x = "Number of looks", y = "Trial count") +
  scale_fill_discrete(name="Trial type")
```

###Social information gathering and referential ambiguity

We next examined children's looking behavior for each trial type across the four phases of the trial. The distribution of number of looks are presented in figure \ref{fig:resultse1}. Note that the most common response is to reference the speaker at least once during the *label* phase, but to not reference the speaker at all during the other phases. To test our prediction that referential ambiguity (i.e., having two novel objects) would produce more looking, we fit mixed-effects linear regression models separately for each phase with the following structure: `number of looks ~ number of objects * familiarity * age in months + (number of objects + familiarity | subject)`. Our initial planned analysis, a single model with phase as a factor, did not converge, and the model was subsequently trimmed according to our standard laboratory analytic procedures. 

We did not find any main or interaction effects of number of objects, familiarity, or age on number of looks during the *label* phase (Figure \ref{fig:resultse1}). Thus, mere novelty or the presence of multiple objects was not enough to increase children's looking when the experimenter was producing the label. Since individuals tend to look at someone who is speaking, children may have looked at the experimenter at least once regardless of lexical ambiguity, minimizing possible condition differences. We also did not observe selective looking during the *slide* phase. However, we found an interaction effect of number of objects and familiarity during the *planning* ($\beta$ = `r broman::myround(p_lm$coefficients[5], 2)`, *p* < .001) and *response* phases ($\beta$ = `r broman::myround(r_lm$coefficients[5], 2)`, *p* < .001), such that NN trials were associated with more looks. 

```{r}
glm_e1_l <- summary(glmer(soc_ref ~ num_objs * familiarity * age_c +
                (1|SID), 
              data = filter(lmer_data, phase_name == "label"), 
              family = "binomial"))

glm_e1_l_tab <- as.data.frame(glm_e1_l$coef)

glm_e1_s <- summary(glmer(soc_ref ~ num_objs * familiarity * age_c +
                (1|SID), 
              data = filter(lmer_data, phase_name == "slide"), 
              family = "binomial"))

glm_e1_s_tab <- as.data.frame(glm_e1_s$coef)

glm_e1_p <- summary(glmer(soc_ref ~ num_objs * familiarity * age_c +
                (1|SID), 
              data = filter(lmer_data, phase_name == "planning"), 
              family = "binomial"))

glm_e1_p_tab <- as.data.frame(glm_e1_p$coef)

glm_e1_r <- summary(glmer(soc_ref ~ num_objs * familiarity + age_c +
                (1|SID), 
              data = filter(lmer_data, phase_name == "response"), 
              family = "binomial"))

glm_e1_r_tab <- as.data.frame(glm_e1_r$coef)
#this last one does not converge with age interaction.
```

As discussed previously, an alternative analytic approach would be to fit a logistic mixed-effects regression predicting *whether or not* children look to the speaker in each phase, rather than the number of times they do so. In support of this approach, the distribution of looks is not normal for the slide, planning, and response phases, with the majority of trials containing no looks to the speaker (Figure \ref{fig:histe1}). To address this issue, we additionally fit separate logistic mixed-effects regressions with the following structure: `look (yes or no) ~ number of objects * familiarity * age in months + (number of objects + familiarity | subject)`. A single model with phase as a factor did not converge. 

The results of these analyses were similar to those of the linear models; number of objects and familiarity interacted in the *planning* and *response* phases such that there was more likely to be a look when there were two novel objects, ($\beta$s = `r broman::myround(glm_e1_p_tab$Estimate[5], 2)`, `r broman::myround(glm_e1_r_tab$Estimate[5], 2)`, *p*s <.05 & <.001). In addition, there was a significant interaction of number and familiarity of objects in the *slide* phase, such that NN trials were less likely to be associated with a look ($\beta$ = `r broman::myround(glm_e1_s_tab$Estimate[5], 2)`, *p* <.05). This latter finding was not predicted, but could reflect children's tendency to look more at novel stimuli, which would trade off with looking at the speaker, particularly when there is no utility to looking at the speaker, as when the objects are being slid across the table.

In summary, children looked to the speaker more often when planning and executing a response under uncertainty. These results suggest that children were aware that they did not have sufficient knowledge to answer independently, and referenced the speaker to resolve this uncertainty.

Notably, and in contrast to Vaish et al., we did not find the expected effect of referential ambiguity in the *label* phase. It is possible that children failed to predict that they would need more information until later in the trial, when they were actually faced with making a decision. Another possibility is that children's looking was at ceiling during the labeling phase, perhaps because older children tend to look at someone who is speaking regardless of the need for referential disambiguation. 

A third possibility is that this finding is an artifact of our design, in which the speaker gazed at the center of the table rather than the referent of the label. Children may have realized that the speaker's gaze direction during labeling was not informative. Relatedly, children may have found it strange to interact with a speaker who did not gaze at the object they were labeling, which may have produced unnatural patterns of looking. Experiment 2 tests these possibilities and further examines whether children's information gathering is sensitive to graded uncertainty.

# Experiment 2

Experiment 2 was designed to achieve several goals; first, we aimed to replicate the finding from Experiment 1 that children reference a social partner on the basis of referential ambiguity while executing a decision. Second, we tested whether children's information gathering is graded with respect to graded evidence about a label's referent. 

To this end, we manipulated two sources of referential evidence. First, we added trials with 1 novel and 1 familiar object (FN) and a novel label. This condition contains evidence about reference since the familiar item can be excluded [@Markman1988], but may not be as conclusive as trials with a familiar target. Thus, we predicted that, in the aggregate, children would show the most looking to the speaker in the NN condition, the least in the FF condition, and an intermediate amount in the FN condition.   
Second, we manipulated between participants whether or not the speaker gazed at the objects they referred to, and thus, whether or not their gaze was an informative cue to reference. We predicted that having access to referential gaze as an informative cue would make children less likely to reference the speaker during their decision, but perhaps more likely to reference the speaker during labeling. Critically, this also allowed us to test whether children's information gathering is selective on the basis of referential ambiguity during labeling if the speaker's gaze is informative, addressing an interpretive issue in Experiment 1. 

Since we did not observe any difference between F and N trials in Experiment 1, we eliminated single-object trials. Additionally, we restricted the sample to 3- and 4-year-olds, as we did not observe developmental differences in Experiment 1. Three- and 4-year-olds were chosen because we planned to include age in months as a continuous variable in our regression models, and contiguous age groups are thus preferable. Furthermore, 2-year-olds seemed to have more difficulty completing the task in Experiment 1, as evidenced by their lower accuracy rate and higher rate of placing two objects in the bucket. 

## Methods

```{r}
rm(list=ls())
load("soc_ref_e2.RData")
```

```{r}
#how many statements of uncertainty and questions?

utterances <- d %>%
  group_by(trial_type)%>%
  summarise(sou = mean(num_sou), ques = mean(num_ques))

missing <- d %>%
  group_by(age_years)%>%
  summarise(excluded = mean(exclude))

missingthree <- missing$excluded[missing$age_years == 3]
missingfour <- missing$excluded[missing$age_years == 4]

age_months <- d %>%
  group_by(age_years) %>%
  multi_boot_standard(col = "age_months")

age_months$age_years <- factor(age_months$age_years,
levels = c(3, 4),
labels = c("three", "four"))
```

### Participants

We recruited a planned sample of 80 children ages 3-4 years from the Children’s Discovery Museum in San Jose, California^[Planned sample size, exclusion criteria, and analysis plan (including model specification) preregistered at https://osf.io/y7mvt/.]. The sample included 40 3-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="three"], 1)` months) and 40 4-year-olds (mean age `r broman::myround(age_months$mean[age_months$age_years=="four"], 1)` months). An additional 20 children participated but were removed from analyses because they heard English less than 75% of the time at home (*n* = 9), because they were unable to complete at least half of the trials in the task (*n* = 7), or due to experimenter or technical errors (*n* = 4).

### Stimuli and Design

The stimuli and design were similar to Experiment 1 but included three trial types: FF, NN, and FN. There were four of each trial type, totaling twelve trials. In addition, we manipulated the experimenter’s gaze behavior between participants. For half of the participants, the experimenter gazed at the center of the table while labeling objects (uninformative gaze); for the remaining half, they gazed directly at the objects they labeled (informative gaze).

### Procedure

The experimental and coding procedures were identical to Experiment 1, except that there were three practice trials (two FF trials and one NN trial). We chose this approach so that children could experience both familiar and novel stimuli during practice, but would not be discouraged by an overly difficult practice session. As in Experiment 1, children were corrected if they chose the wrong object on FF trials but not NN trials. 

We again noted trials that should be excluded based on the same criteria as in Experiment 1. We excluded `r broman::myround(missingthree*100, 1)`% of trials from 3-year-olds and no trials from 4-year-olds. Inter-rater reliability for the number of looks in each phase was again high, intraclass correlation *r* = .97, *p* < .001. 
The mean durations of the phases for Experiment 2 are presented in Table \ref{tab:phases}. They varied in length according to the same pattern as in Experiment 1. 

## Results and Discussion

###Accuracy

```{r}
d$acc <- as.numeric(as.character(d$acc))

acc_mss_e2 <- d%>%
  filter(!is.na(acc), exclude == 0)%>%
  group_by(trial_type, Gaze, age_years)%>%
  multi_boot_standard(col = "acc", na.rm = TRUE)%>%
  mutate(Exp = "2")

acc_mss_e2$Gaze <- factor(acc_mss_e2$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Gaze", "No gaze"))

acc_mss_e2$trial_type <- factor(acc_mss_e2$trial_type,
levels = c("familiar","mutual", "novel"),
labels = c("FF", "FN", "NN"))

acc_mss_e2$age_years <- as.factor(acc_mss_e2$age_years)
```

```{r acce2, fig.env='figure*',fig.width=6, fig.height=3, fig.cap='Accuracy for trials with a correct answer available (FF and FN, and all gaze trials) in Experiment 2. Error bars are 95 percent confidence intervals.'}
ggplot(acc_mss_e2, aes(age_years, mean, fill=trial_type)) +
  geom_bar(stat="identity", position = "dodge") + 
  geom_linerange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
             position = position_dodge(width = .9)) + 
  facet_wrap(~ Gaze)  +
  ggthemes::theme_few() + 
  labs(x = "Age in Years", y = "Accuracy") +
  scale_fill_discrete(name="Trial type")
```

```{r echo = FALSE}
#how often did children select two objects or no objects?
ids <- d %>%
 distinct(SID)

trials <- d %>%
 distinct(trial)

n <- length(ids$SID)*length(trials$trial)
n_two <- n #number of two-object trials
n_two_group <- n_two/2 #number of two-object trials per age group

res <- d %>%
  distinct(SID, trial, response_orig, trial_type, acc, age_years)

#how often do kids pick 2 objects on 2-object trials?
nc <- length(res$acc[res$response_orig == "NC"])/n_two
b <- length(res$acc[res$response_orig == "B"])/n_two
lr <- length(res$acc[res$response_orig == "LR"])/n_two
rl <- length(res$acc[res$response_orig == "RL"])/n_two
tot <- 100*(lr + rl + b) #percent of trials with two objects placed in bucket

b3 <- length(res$acc[res$response_orig == "B" & res$age_years == 3])/n_two_group
b4 <- length(res$acc[res$response_orig == "B" & res$age_years == 4])/n_two_group

lr3 <- length(res$acc[res$response_orig == "LR" & res$age_years == 3])/n_two_group
lr4 <- length(res$acc[res$response_orig == "LR" & res$age_years == 4])/n_two_group

rl3 <- length(res$acc[res$response_orig == "RL" & res$age_years == 3])/n_two_group
rl4 <- length(res$acc[res$response_orig == "RL" & res$age_years == 4])/n_two_group

tot3 <- 100*(lr3 + rl3 + b3) #percent of 2obj trials with two objects placed in bucket
tot4 <- 100*(lr4 + rl4 + b4) #percent of 2obj trials with two objects placed in bucket

#are trials with 2 objects chosen more likely to be novel?

nov_t <- d %>%
  distinct(SID, trial, response_orig, trial_type, acc, age_years, Gaze)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL" | response_orig == "B",
         unambiguous = trial_type == "mutual" | trial_type == "familiar" | Gaze == "gaze")%>%
  group_by(SID, age_years, trial_type)%>%
  summarise(both = mean(both))

nov <- d %>%
  distinct(SID, trial, response_orig, trial_type, acc, age_years, Gaze)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL" | response_orig == "B",
         unambiguous = trial_type == "mutual" | trial_type == "familiar" | Gaze == "gaze")%>%
  group_by(age_years, unambiguous)%>%
  summarise(both = mean(both))

#not enough observations for t-test

#when kids put two objects in bucket, do they put the correct one in first if there is a correct answer?

cor <- d %>%
  filter(!is.na(acc), response_orig != "B")%>%
  distinct(SID, trial, response_orig, trial_type, acc, age_years)%>%
  mutate(both = response_orig == "LR" | response_orig == "RL")

cor$acc <- as.numeric(cor$acc)

acc_sum <- cor%>%
  filter(acc == 1)%>%
  group_by(age_years)%>%
  summarize(both = sum(both))

both_sum <- cor%>%
  group_by(age_years)%>%
  summarize(both = sum(both))
```

```{r}
lmer_data <- d %>%
  filter(!exclude) %>%
  mutate(trial_type = factor(trial_type), 
         age_c = as.numeric(langcog::scale(age_months, scale=FALSE)),
         phase_name = factor(phase_name), 
         gaze = factor(Gaze),
         acc = factor(acc),
         soc_ref = social_ref)
```

```{r}
lmer_data$trial_type <- relevel(lmer_data$trial_type, ref = "familiar")
lmer_data$gaze <- relevel(lmer_data$gaze, ref = "no_gaze")

acc_mod <- summary(glmer(acc ~ trial_type * gaze + age_c  +
                           (1| SID), 
                         data = lmer_data,
                       family = "binomial"))
```

Children's accuracy for trials with a correct answer possible (i.e., FF, FN, and all trials with gaze) was calculated using the same criteria as in Experiment 1 (Figure \ref{fig:acce2}). Children sometimes put two items in the bucket, although they did so less frequently than in Experiment 1, perhaps because there were two objects available on every trial and it was thus less of a novelty (3-year-olds: `r broman::myround(tot3, 1)`% of trials; 4-year-olds: `r broman::myround(tot4, 1)`%). As in Experiment 1, the first item they placed in the bucket was coded as their response. To quantify the effects of familiarity, gaze, and age on accuracy, we fit the following mixed-effects logistic regression model: `correct ~ trial type * gaze + age in months + (1| subject)`. Accuracy was significantly lower for NN ($\beta$ = `r broman::myround(acc_mod$coefficients[2], 2)`, *p* < .001) and FN trials ($\beta$ = `r broman::myround(acc_mod$coefficients[3], 2)`, *p* < .001) compared to FF trials, and trial type interacted with gaze condition such that accuracy was significantly higher in the gaze condition for NN ($\beta$ = `r broman::myround(acc_mod$coefficients[6], 2)`, *p* < .001) and FN trials ($\beta$ = `r broman::myround(acc_mod$coefficients[7], 2)`, *p* < .001). Age did not significantly predict accuracy ($\beta$ = `r broman::myround(acc_mod$coefficients[5], 2)`, *p* = .12). 

###Information gathering and referential ambiguity

```{r}
lmer_data$trial_type <- relevel(lmer_data$trial_type, ref = "mutual")

lm_l <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "label")))

lm_s <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "slide")))

lm_p <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "planning")))

lm_r <- summary(lmer(num_looks ~ trial_type *  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "response")))

##########

#logistic regressions
glm_l <- summary(glmer(soc_ref ~ trial_type +  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "label"),
                       family = "binomial"))

glm_s <- summary(glmer(soc_ref ~ trial_type +  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "slide"),
                       family = "binomial"))

glm_p <- summary(glmer(soc_ref ~ trial_type +  age_c * gaze  +
                           (1 | SID), 
                         data = filter(lmer_data, phase_name == "planning"),
                       family = "binomial"))

glm_r <- summary(glmer(soc_ref ~ trial_type +  age_c * gaze  +
                           (1| SID), 
                         data = filter(lmer_data, phase_name == "response"),
                       family = "binomial"))
```

Experiment 2 was designed to test whether different amounts of referential evidence elicit differential amounts of social information gathering. This would suggest that young children are sensitive to graded evidence for a hypothesis (e.g., that this object is the "blicket"). The amount of referential evidence was manipulated through the familiarity of objects presented (NN vs FN vs FF trials) and whether or not gaze was informative (gaze vs. no gaze). If children are sensitive to graded evidence, we might expect a pattern of looking that conforms to (NN > FN > FF) and (no gaze > gaze), with the possibility of an interaction between gaze condition and familiarity.

Children's patterns of looking based on familiarity and gaze condition are presented in Figure \ref{fig:resultse2}. To quantify the main and interactive effects of familiarity, gaze condition, and age on children's looking, we fit separate mixed-effects linear regression models for each phase (label, planning, slide, response) with the following structure: `number of looks ~ familiarity * age in months * gaze + (1 | subject)`.

We found no effect of familiarity, gaze condition, or age on looking in the *label* or *slide* phases. In the *slide* phase, FF trials elicited less looking ($\beta$ = `r broman::myround(lm_s$coefficients[2], 2)`, *p* < .01) and NN trials elicited more looking ($\beta$ = `r broman::myround(lm_s$coefficients[3], 2)`, *p* = .047) compared to FN trials, and there were no effects of or interactions with gaze condition or age. In the *planning* phase, we also found that FF trials were associated with less looking than FN trials ($\beta$ = `r broman::myround(lm_p$coefficients[2], 2)`, *p* = .045) and NN trials were associated with more looking compared to FN trials ($\beta$ = `r broman::myround(lm_p$coefficients[3], 2)`, *p* < .01), and there were no effects of or interactions with gaze condition or age. In the *response* phase, FF trials elicited less looking ($\beta$ = `r broman::myround(lm_r$coefficients[2], 2)`, *p* < .001) and NN trials elicited more looking ($\beta$ = `r broman::myround(lm_r$coefficients[3], 2)`, *p* = .02) compared to FN trials. In addition, the gaze condition was associated with less looking compared to the no-gaze condition ($\beta$ = `r broman::myround(lm_r$coefficients[5], 2)`, *p* = .03), and gaze interacted with familiarity such that FF trials in the gaze condition were associated with more looking than FF trials in the no-gaze condition ($\beta$ = `r broman::myround(lm_r$coefficients[8], 2)`, *p* < .01). 

In summary, in the *slide*, *planning*, and *response* phases, children showed the pattern of responding with respect to graded evidence that we predicted. As in Experiment 1, they looked more at the speaker for NN trials compared to FF trials. In addition, they showed an intermediate amount of looking for FN trials, when the referent was novel but the distracter could be excluded because it was familiar, providing more evidence than NN trials but less than FF trials. They also looked more at the experimenter when she did not gaze at the correct object during labeling, suggesting that children attended to this evidence and it affected their certainty in their response. Additionally, familiarity interacted with gaze condition, such that FF trials with referential gaze elicited more looking than FF trials without referential gaze. Although we did not predict this result, it is possible that children were more likely to seek feedback when they were very certain (i.e., when the target was familiar) from a speaker whose gaze patterns were more naturalistic (i.e., gazing at the referent of one's speech).

Finally, we did not observe selective looking during the *label* phase, even when referential gaze was available. This result rules out the possibility that children are less selective during labeling because they learn that gaze direction was not informative. Instead, young children may attend to someone who is speaking regardless of the need for disambiguation. 

As in Experiment 1, we additionally fit mixed-effects logistic regressions with looking quantified as a binary variable (look vs. no look) for each phase, since the number of looks was not normally distributed (Figure \ref{fig:histe1}). The model had the following structure: `look (yes or no) ~ trial type + age group + (number of objects + familiarity | subject)`. We observed a similar pattern of results compared to the linear models, except that the difference between FF and FN trials was not significant in the response phase. Additionally, similar to Experiment 1, there was an effect of trial type in the *slide* phase such that children looked at the experimenter more for FF trials.

```{r}
#get means for plot
msslooks <- filter(d, exclude == 0) %>%
  group_by(SID, phase_name, trial_type, Gaze, age_years) %>%
  summarise(num_looks = mean(num_looks))

mslooks <- filter(d, exclude == 0) %>%
  group_by(phase_name, trial_type, Gaze, age_years) %>%
  multi_boot_standard(col = "num_looks") 

msslooks$phase_name <- factor(msslooks$phase_name, levels = c("label","slide", "planning", "response"))
mslooks$phase_name <- factor(mslooks$phase_name, levels = c("label","slide", "planning", "response"))

msslooks$trial_type <- factor(msslooks$trial_type, labels = c("FF","FN", "NN"))
mslooks$trial_type <- factor(mslooks$trial_type, labels = c("FF","FN", "NN"))

msslooks$Gaze <- factor(msslooks$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Referential gaze", "No referential gaze"))

mslooks$Gaze <- factor(mslooks$Gaze,
levels = c("gaze","no_gaze"),
labels = c("Referential gaze", "No referential gaze"))

msslooks$age_years <- factor(msslooks$age_years,
levels = c(3, 4),
labels = c("3 years", "4 years"))

mslooks$age_years <- factor(mslooks$age_years,
levels = c(3, 4),
labels = c("3 years", "4 years"))

msslooks <- msslooks %>%
  mutate(familiarity = trial_type)

mslooks <- mslooks %>%
  mutate(familiarity = trial_type)
```

```{r resultse2, fig.width=8, fig.height=5, fig.cap='Results of Experiment 2. Number of looks to the experimenter based on phase, trial type, gaze condition, and age. Age in months was entered as a continuous variable in regression models but is presented here as a categorical variable for visual simplicity. Error bars are 95 percent confidence intervals.'}

ggplot(msslooks, aes(x = phase_name, y = num_looks, 
               col = familiarity, group = familiarity)) + 
  geom_line(data = mslooks, aes(y = mean)) + 
  geom_pointrange(data = mslooks, 
                  aes(y = mean, ymin = summary_ci_lower, ymax = summary_ci_upper, shape = familiarity), 
                  position = position_dodge(width =.1)) + 
  facet_grid(age_years ~ Gaze) + 
  scale_y_continuous(limits=c(0,2), breaks=c(0,1,2)) +
  theme(axis.text.x = element_text(angle = 0, hjust = .5, vjust = .5))+ 
  labs(x = "Phase", y = "Number of Looks")  +
  ggthemes::theme_few() 
```

#General Discussion

During the preschool years, children are increasingly able to actively gather information through help-seeking and exploration [@Chouinard2007; @Schulz2007]. They are also increasingly proficient at explicitly identifying their gaps in knowledge and their uncertainty in various domains [@Hembacher2014; @Coughlin2014; @Lyons2011a; @Rohwer2012]. Do young children similarly identify lexical ambiguity and engage in appropriate active learning behaviors in response? Here, we examined whether young children's social information gathering was associated with referential uncertainty in situations in which the referent was either completely novel or familiar (Experiment 1), and when there were differing amounts of referential evidence (Experiment 2). 

We found that referential ambiguity was strongly associated with children's information gathering behavior. Specifically, we observed this selectivity when children were planning and executing their decision. We speculate that children referenced the speaker during the decision process because they expected evaluative feedback about their demonstrated choice, either implicitly through the adult’s facial expressions, or through an explicit response. This idea is consistent with other recent findings that preschoolers and toddlers seek help selectively when a problem is difficult or they are less skilled [@Goupil2016; @Vredenburgh2015].

In Experiment 2, we also found that children's information-seeking reflected graded referential evidence. In the case of FN trials, children could solve the problem of reference by excluding the familiar item [@Markman1988; @Merriman1989], and indeed, they chose the correct object most of the time for these trials. If children simply monitored the presence or absence of such cues, they would have consistently responded to FN trials with certainty. Instead, they sought information in a graded fashion, looking at the experimenter less than for NN trials but more than for FF trials. Overall, they also exhibited more looking when referential gaze was present than when it was not. Intriguingly, children appear to remain uncertain when their only cue to reference is the adult's gaze during labeling — there was no difference between NN trials with and without gaze. This finding suggests that young children may remain subjectively uncertain about new label-object mappings if they have not yet encountered additional evidence or received confirmation of their accuracy. 

These findings are important given that being able to monitor the likelihood of accuracy based on graded evidence is assumed important for decision-making and behavioral regulation across development [@Yeung2012; @Krebs2010]. Being able to monitor graded epistemic uncertainty allows individuals to gate out information that does not meet a criterion level of certainty based on individual goals or task demands [@Koriat1996]. The current findings are consistent with the possibility that preschoolers engage in this type of reasoning, given that their uncertainty tracked quantitatively with the amount of evidence available. 

On the other hand, we found no evidence for selective information gathering while the speaker was producing the label. One possibility is that young children do not recognize the need for disambiguating information until they need to make a decision [@Markman1977]. Another possibility is that children spontaneously look at a speaker regardless of ambiguity, and additional looking was not necessary or possible. This latter possibility seems more credible, given that children looked at the speaker at least once during labeling on most trials. Notably, Vaish et al. observed selective referencing during labeling among infants. Since infants in that study were holding one of the objects during labeling, referencing the speaker would have required them to disengage from that object, and may therefore have been more costly, promoting selectivity. Future research with preschoolers that includes a greater trade-off between attentional options would help to distinguish among these possibilities. 

Contrary to our expectations, we did not observe developmental differences in children's information seeking. We sampled a broad age range (2 to 5 years) due to previous evidence for improvements in metacognitive performance during the preschool years [@Hembacher2014; @Coughlin2014; @Lyons2011a; @Rohwer2012]. However, we found that 2-year-olds were equally likely to be selective in their information seeking compared to 5-year-olds. There are several possible explanations for this finding. On the one hand, it could be that children's monitoring of lexical ambiguity and ability to selectively seek out disambiguating evidence are both firmly in place by age 2, and do not develop in the following years. Indeed, there is evidence from Vaish et al. that infants ages 13 and 18 months selectively reference a speaker's gaze direction when her referent is ambiguous, suggesting that sensitivity to lexical uncertainty is early developing. Children have already acquired a substantial vocabulary by age 2, so if lexical uncertainty monitoring is an important factor in language acquisition, it is not surprising that 2-year-olds demonstrate this ability.

Another possibility is that children's awareness of uncertainty (in the linguistic domain and beyond) becomes more concrete throughout early childhood, but that information-seeking is a particularly sensitive measure of uncertainty monitoring compared to explicit report (see Kloo et al. for a similar argument). Developmental differences in information-seeking could be minimal because they do not rely as strongly on later-developing metacognitive processes. 

The behavior we examined here, selective social information-gathering, could fall into a spectrum of active learning behaviors starting in infancy. Infants direct their attention to salient aspects of the environment that are most likely to yield information, including faces and hands. As infants learn to locomote, first by crawling and then by walking, they have access to a broader set of information. As children learn to speak and can more easily manipulate objects in the environment, they have more opportunity still to seek out information to disambiguate areas of uncertainty. This physical development may procede in parallel to metacognitive advancements that allow children to more acutely identify gaps in knowlege when they can then seek to fill. The present investigation illustrates one piece in the puzzle of children's developing contributions to their own learning.

There are limitations to the current investigation. First, although we assume that children hoped to glean disambiguating information from the adult experimenter when they visually referenced her, we do not know what type of evidence evidence they expected to receive (e.g., direct help, informative gaze, or an affective response). This is especially relevant as children of different ages, despite showing the same patterns of looking, might have had distinct expectations about the type of information or help they would receive. Additionally, in Experiment 1, children sometimes ignored the instruction to place only one item in the bucket, particularly the 2-year-olds. Although we speculate that younger children showed this behavior because they found it entertaining to place both objects in the bucket, this behavior could also reflect a different understanding or approach to the task compared to older children. 

Overall, these results provide further evidence that preschool-aged children monitor graded uncertainty in their mental representations generally, and in lexical ambiguity specifically. Furthermore, they act on that uncertainty through spontaneous information-seeking. These behaviors may in part underlie the rapid acquisition of language during early childhood. 

# Acknowledgements

We thank Veronica Cristiano for assisting with data collection. EH was supported by a generous gift from Kinedu SAPI de CV. 

# References 

```{r}

```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent


```{r}
rm(list=ls())
load("soc_ref_e1.RData")

lmer_data <- d %>%
  filter(!exclude) %>%
  mutate(num_objs = factor(num_objs), 
         familiarity = factor(familiarity), 
         age_c = as.numeric(langcog::scale(age_months, scale=FALSE)),
         phase_name = factor(phase_name),
         soc_ref = social_ref)

l_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "label")))

s_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "slide")))

p_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs  | SID),
           data = filter(lmer_data, phase_name == "planning")))

r_lm <- summary(lmer(num_looks ~ num_objs * familiarity * age_c +
             (num_objs | SID),
           data = filter(lmer_data, phase_name == "response")))
```


Table S1
```{r e1_table_l, results="asis", tab.cap = NULL}
#label
e1_l.tab <- as.data.frame(l_lm$coef)

e1_l.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_l.tab$Phase <- c("Label",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_l.tab) <- NULL
e1_l.tab <- e1_l.tab[,c(7,6,1:2,4:5)]
names(e1_l.tab)[4:5] <- c("$t$ value","$p$ value")

#slide
e1_s.tab <- as.data.frame(s_lm$coef)

e1_s.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_s.tab$Phase <- c("Slide",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_s.tab) <- NULL
e1_s.tab <- e1_s.tab[,c(7,6,1:2,4:5)]
names(e1_s.tab)[4:5] <- c("$t$ value","$p$ value")

#planning
e1_p.tab <- as.data.frame(p_lm$coef)

e1_p.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_p.tab$Phase <- c("Planning",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_p.tab) <- NULL
e1_p.tab <- e1_p.tab[,c(7,6,1:2,4:5)]
names(e1_p.tab)[4:5] <- c("$t$ value","$p$ value")

#response
e1_r.tab <- as.data.frame(r_lm$coef)

e1_r.tab$Predictor <- c("Intercept",
                      "Num objs (2)",
                      "Fam (N)",
                      "Age",
                      "Num objs (2) * Fam (N)",
                      "Num objs (2) * Age",
                      "Fam (N) * Age",
                      "Num objs (2) * Fam (N) * Age")

e1_r.tab$Phase <- c("Response",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "",
                      "")

rownames(e1_r.tab) <- NULL
e1_r.tab <- e1_r.tab[,c(7,6,1:2,4:5)]
names(e1_r.tab)[4:5] <- c("$t$ value","$p$ value")

e1.tab <- bind_rows(e1_l.tab, e1_s.tab)%>%
  bind_rows(e1_p.tab)%>%
  bind_rows(e1_r.tab)

e1.tab %<>% 
  mutate(
    stars = ifelse(`$p$ value` > .1, "", 
                   ifelse(`$p$ value` < .001, "***",
                          ifelse(`$p$ value` < .01, "**",
                                 ifelse(`$p$ value` < .05, "*",
                                        ifelse(`$p$ value` < .1, ".", "Error"))))),
    `$p$ value` = ifelse(`$p$ value` > .1, round(`$p$ value`, 2), 
                         ifelse(`$p$ value` < .001, "$<$ .001",
                                ifelse(`$p$ value` < .01, round(`$p$ value`, 2),
                                       ifelse(`$p$ value` < .05, round(`$p$ value`, 2),
                                              ifelse(`$p$ value` < .1, round(`$p$ value`, 2), 
                                                     "Error")))))
  )

names(e1.tab)[7] <- c("")

italic <- function(x){
paste0('{\\emph{',x, '}}')
}

print(xtable(e1.tab,
             align = c("l","l","l","r","r","r","r", "l"),
             caption = italic("Results from separate linear mixed-effects models predicting social referencing for the label, slide, planning, and response phases in Experiment 1.")),
      include.rownames=FALSE,
      hline.after=c(-1,0,nrow(e1_l.tab),nrow(e1_l.tab)*2, nrow(e1_l.tab)*3, nrow(e1_l.tab)*4),
      caption.placement = 'top',
      sanitize.text.function=function(x){x},
      comment = FALSE)
```
*Note*: Parentheticals indicate the reference level for dummy-coded variables.

